{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create file structure for raster datasets.\n",
    "\n",
    "The folowing cell assumes several manual steps prior to running.  First it assumes the GEE script was run to completion and that within a base folder (in this case 'D:\\new_imagery') a user has created three sub folders titled 2016, 2017, and 2019 respectively. Within each sub folder, a four subfolders with the titles 66, 95, 131, and 160 (the numbers of all the satellite orbits) have been subsequently manually created.  Then after manually downloading the GEE data from the users google drive, the data for each year should be placed into the sub-folder corresponding to the year.  If this has been done, the next cell will move all the folders to their orbit subfolders automatically, and will prepare the user for the folder structure that the remaining ArcPy processing steps will demand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "years = [2016,2017, 2019]\n",
    "\n",
    "for year in years:\n",
    "    base_folder = 'D:\\\\new_imagery\\\\{}'.format(year)\n",
    "\n",
    "    for folder in os.listdir(base_folder):\n",
    "        if 'Tromsoe' in folder:\n",
    "            files = os.listdir('{}\\\\{}'.format(base_folder, folder))\n",
    "            path = files[0].split('_')[-1].split('.')[0]\n",
    "        \n",
    "            source = '{}\\\\{}'.format(base_folder, folder)\n",
    "            dest = '{}\\\\{}'.format(base_folder, path, folder)\n",
    "            print('moving {} to {}'.format(source, dest))\n",
    "        \n",
    "            shutil.move(source, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create local file geodatabases to store and process the raster data. \n",
    "\n",
    "This scipt iterates through the folders of all the dates and orbits where SAR data was acquired to create three different change detection images as well as to ptoject all the rasters into a PCS (UTM 33 N).  The three change detection images are three different RGB compositions that can be used to develop training data as well as visually assess if an avalanche has occurred. They are composed as follows:\n",
    "\n",
    "- original change detection image: \n",
    "\n",
    "    - This is an RGB composite using VV backscatter images with the prior acquisition date of a given orbit in the R and B channels and the current (or activity) VV backscatter raster in the G channel.\n",
    "\n",
    "\n",
    "- exaggerated change detection (TfMSSmall transformations):\n",
    "\n",
    "    - This RGB composite with VVact-VVref in R and VHact-VHref in the B and the product of the rescales squares of each individual image in the G channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "\n",
    "arcpy.env.overwriteOutput=True\n",
    "\n",
    "def get_path_dts(orbit_folder):\n",
    "    dates = []\n",
    "    dirs = [d for d in os.listdir(orbit_folder) if os.path.isdir('{}\\\\{}'.format(orbit_folder, d))]\n",
    "    for fldr in dirs:\n",
    "        date = fldr.split('_')[-1].split('-')\n",
    "        dt = datetime.datetime(int(date[0]), int(date[1]), int(date[2]))\n",
    "        dates.append(dt)\n",
    "    return dates\n",
    "\n",
    "def two_dig(num):\n",
    "    if len(str(num)) == 2:\n",
    "        return num\n",
    "    elif len(str(num)) == 1:\n",
    "        return '0{}'.format(num)\n",
    "    \n",
    "def generate_rasters(ref_vv, act_vv, ref_vh, act_vh, out_gdb):\n",
    "    \n",
    "    try:\n",
    "        arcpy.env.workspace = arcpy.env.scratchGDB\n",
    "        print('executing minus functions')\n",
    "        vv_minus = Minus(act_vv, ref_vv)\n",
    "        vh_minus = Minus(act_vh, ref_vh)\n",
    "        \n",
    "        print('executing intitial rescale ')\n",
    "        vv_minus_rescale_1_255 = RescaleByFunction(vv_minus, TfLinear(), from_scale=1, to_scale=255)\n",
    "        vh_minus_rescale_1_255 = RescaleByFunction(vh_minus, TfLinear(), from_scale=1, to_scale=255)\n",
    "    \n",
    "        vv_minus_rescale_0_1_linear = RescaleByFunction(vv_minus, TfLinear(), from_scale=0, to_scale=1)\n",
    "        vh_minus_rescale_0_1_linear = RescaleByFunction(vh_minus, TfLinear(), from_scale=0, to_scale=1)\n",
    "    \n",
    "        vv_minus_rescale_0_1_mssmall = RescaleByFunction(vv_minus, TfMSSmall(), from_scale=0, to_scale=1)\n",
    "        vh_minus_rescale_0_1_mssmall = RescaleByFunction(vh_minus, TfMSSmall(), from_scale=0, to_scale=1)\n",
    "        \n",
    "        print('executing square functions')\n",
    "        vv_square_linear = Square(vv_minus_rescale_0_1_linear)\n",
    "        vh_square_linear = Square(vh_minus_rescale_0_1_linear)\n",
    "    \n",
    "        vv_square_mssmall = Square(vv_minus_rescale_0_1_mssmall)\n",
    "        vh_square_mssmall = Square(vh_minus_rescale_0_1_mssmall)\n",
    "        \n",
    "        print('executing times functions')\n",
    "        linear_times = Times(vv_square_linear, vh_square_linear)\n",
    "        mssmall_times = Times(vv_square_mssmall, vh_square_mssmall)\n",
    "    \n",
    "        linear_times_rgb = RescaleByFunction(linear_times, TfLinear(), from_scale=1, to_scale=255)\n",
    "        mssmall_times_rgb = RescaleByFunction(mssmall_times, TfLinear(), from_scale=1, to_scale=255)\n",
    "        \n",
    "        print('generating composite rasters')\n",
    "        arcpy.management.CompositeBands([ref_vv, \n",
    "                                         act_vv, \n",
    "                                         ref_vv], \n",
    "                                         '{}\\\\original_change_detection'.format(out_gdb))\n",
    "        \n",
    "        arcpy.management.CompositeBands([vv_minus_rescale_1_255, \n",
    "                                         linear_times_rgb, \n",
    "                                         vh_minus_rescale_1_255], \n",
    "                                         '{}\\\\training_image_linear_composite'.format(out_gdb))\n",
    "        \n",
    "        arcpy.management.CompositeBands([vv_minus_rescale_1_255, \n",
    "                                         mssmall_times_rgb, \n",
    "                                         vh_minus_rescale_1_255], \n",
    "                                         '{}\\\\training_image_mssmall_composite'.format(out_gdb))\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "def generate_training_shapes(gdb):\n",
    "    \n",
    "    arcpy.management.CreateFeatureclass(gdb, \n",
    "                                        'training_rectangles', \n",
    "                                        'POLYGON', \n",
    "                                        spatial_reference=arcpy.SpatialReference(32633))\n",
    "                    \n",
    "    arcpy.management.AddField('{}\\\\training_rectangles'.format(gdb), 'classvalue', 'LONG')\n",
    "    \n",
    "    arcpy.management.CreateFeatureclass(gdb, \n",
    "                                        'training_polys', \n",
    "                                        'POLYGON', \n",
    "                                        spatial_reference=arcpy.SpatialReference(32633))\n",
    "                    \n",
    "    arcpy.management.AddField('{}\\\\training_polys'.format(gdb), 'classvalue', 'LONG')\n",
    "\n",
    "years = ['2016', '2017', '2019']\n",
    "orbits = ['66', '95', '131', '160']\n",
    "\n",
    "for year in years:\n",
    "    for orbit in orbits:\n",
    "        base_folder = 'D:\\\\new_imagery\\\\{}\\\\{}'.format(year, orbit)\n",
    "        avy_dates = get_path_dts(base_folder)\n",
    "        for date in avy_dates:\n",
    "            folder = 'S1_Tromsoe_DEM_surface_buf_0_date_{}-{}-{}'.format(date.year, two_dig(date.month), two_dig(date.day))\n",
    "            \n",
    "            # set workspace to the folder with the downloded raster data\n",
    "            workspace = '{}\\\\{}'.format(base_folder, folder)\n",
    "            \n",
    "            arcpy.env.workspace = workspace\n",
    "            \n",
    "            # create a file gdb in every folder for which there is avy data\n",
    "            gdb = arcpy.management.CreateFileGDB(workspace, \n",
    "                                                 'avy_data_{}_{}_{}.gdb'.format(date.year, date.month, date.day))[0]\n",
    "            print('creating {}'.format(gdb))\n",
    "            \n",
    "            out_sr = arcpy.SpatialReference(32633) # UTM_33_North\n",
    "            in_sr = arcpy.SpatialReference(4326) # WGS 1984\n",
    "            \n",
    "            # project all the rasters into the proper coordinate system and store in file gdb\n",
    "            for raster in arcpy.ListRasters():\n",
    "                \n",
    "                clean_raster = raster.split('.')[0].replace('-', '_')\n",
    "                out_raster = '{}\\\\{}_projected'.format(gdb, clean_raster) # basename of raster as gdb featureclass\n",
    "                print('creating {}'.format(out_raster))\n",
    "                \n",
    "                arcpy.management.ProjectRaster(raster, \n",
    "                                               out_raster, \n",
    "                                               out_coor_system=out_sr, \n",
    "                                               resampling_type='NEAREST',\n",
    "                                               in_coor_system=in_sr)\n",
    "            \n",
    "        for i in range(len(avy_dates)-1):\n",
    "            \n",
    "            ref_date = avy_dates[i]\n",
    "            act_date = avy_dates[i+1]\n",
    "            \n",
    "            ref_folder = folder = 'S1_Tromsoe_DEM_surface_buf_0_date_{}-{}-{}'.format(ref_date.year, \n",
    "                                                                                      two_dig(ref_date.month), \n",
    "                                                                                      two_dig(ref_date.day))\n",
    "            \n",
    "            act_folder = folder = 'S1_Tromsoe_DEM_surface_buf_0_date_{}-{}-{}'.format(act_date.year, \n",
    "                                                                                      two_dig(act_date.month), \n",
    "                                                                                      two_dig(act_date.day))\n",
    "            \n",
    "            ref_gdb = '{}\\\\{}\\\\avy_data_{}_{}_{}.gdb'.format(base_folder,\n",
    "                                                         ref_folder,\n",
    "                                                         ref_date.year,\n",
    "                                                         ref_date.month,\n",
    "                                                         ref_date.day)\n",
    "            \n",
    "            act_gdb = '{}\\\\{}\\\\avy_data_{}_{}_{}.gdb'.format(base_folder, \n",
    "                                                         act_folder, \n",
    "                                                         act_date.year,\n",
    "                                                         act_date.month,\n",
    "                                                         act_date.day)\n",
    "            \n",
    "            vv_base = 'VV_sigma0_'\n",
    "            vh_base = 'VH_sigma0_'\n",
    "            \n",
    "            vv_act = '{}\\\\{}{}_{}_{}_{}_projected'.format(act_gdb, \n",
    "                                                        vv_base, \n",
    "                                                        act_date.year, \n",
    "                                                        two_dig(act_date.month),\n",
    "                                                        two_dig(act_date.day),\n",
    "                                                        orbit)\n",
    "            vv_ref = '{}\\\\{}{}_{}_{}_{}_projected'.format(ref_gdb, \n",
    "                                                        vv_base, \n",
    "                                                        ref_date.year, \n",
    "                                                        two_dig(ref_date.month),\n",
    "                                                        two_dig(ref_date.day),\n",
    "                                                        orbit)\n",
    "            vh_act = '{}\\\\{}{}_{}_{}_{}_projected'.format(act_gdb, \n",
    "                                                        vh_base, \n",
    "                                                        act_date.year, \n",
    "                                                        two_dig(act_date.month),\n",
    "                                                        two_dig(act_date.day),\n",
    "                                                        orbit)\n",
    "            vh_ref = '{}\\\\{}{}_{}_{}_{}_projected'.format(ref_gdb, \n",
    "                                                        vh_base, \n",
    "                                                        ref_date.year, \n",
    "                                                        two_dig(ref_date.month),\n",
    "                                                        two_dig(ref_date.day),\n",
    "                                                        orbit)\n",
    "            \n",
    "            generate_rasters(vv_ref, vv_act, vh_ref, vh_act, act_gdb)\n",
    "            generate_shapes(act_gdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Export Training data and Build UNET Model\n",
    "\n",
    "Following the structure of the geodatabases developed in a step 2, this script assumes that all possible masks have been developed in feature classes called 'training_polys' in each geodatabase that stores the processed SAR data.  This script will iterate through the gdb's, and export all the training data based on these masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "import shutil\n",
    "\n",
    "arcpy.env.overwriteOutput=True\n",
    "\n",
    "def populate_field(gdb):\n",
    "          \n",
    "    polys = '{}\\\\training_polys'.format(gdb)\n",
    "    p_count = arcpy.management.GetCount(polys)[0]\n",
    "    if int(p_count) > 0:\n",
    "        arcpy.management.CalculateField(polys, 'classvalue', 1)\n",
    "\n",
    "def get_path_dts(orbit_folder):\n",
    "    dates = []\n",
    "    dirs = [d for d in os.listdir(orbit_folder) if os.path.isdir('{}\\\\{}'.format(orbit_folder, d))]\n",
    "    for fldr in dirs:\n",
    "        date = fldr.split('_')[-1].split('-')\n",
    "        dt = datetime.datetime(int(date[0]), int(date[1]), int(date[2]))\n",
    "        dates.append(dt)\n",
    "    return dates\n",
    "\n",
    "def two_dig(num):\n",
    "    if len(str(num)) == 2:\n",
    "        return num\n",
    "    elif len(str(num)) == 1:\n",
    "        return '0{}'.format(num)\n",
    "    \n",
    "def has_detections(gdb):\n",
    "\n",
    "    polys = '{}\\\\training_polys'.format(gdb)\n",
    "    p_count = arcpy.management.GetCount(polys)[0]\n",
    "    if int(p_count) > 0:\n",
    "        return int(p_count)\n",
    "    else:\n",
    "        return 0\n",
    "x=0\n",
    "years = ['2016', '2017', '2019']\n",
    "orbits = ['66', '95', '131', '160']\n",
    "for year in years:\n",
    "    for orbit in orbits:\n",
    "        base_folder = 'D:\\\\new_imagery\\\\{}\\\\{}'.format(year, orbit)\n",
    "        avy_dates = get_path_dts(base_folder)\n",
    "        for date in avy_dates:\n",
    "            folder = 'S1_Tromsoe_DEM_surface_buf_0_date_{}-{}-{}'.format(date.year, \n",
    "                                                                        two_dig(date.month), \n",
    "                                                                        two_dig(date.day))\n",
    "            gdb = '{}\\\\{}\\\\avy_data_{}_{}_{}.gdb'.format(base_folder, \n",
    "                                                         folder, \n",
    "                                                         date.year, \n",
    "                                                         date.month, \n",
    "                                                         date.day)\n",
    "            num = has_detections(gdb)\n",
    "            if num > 0:\n",
    "                x+=num\n",
    "                print(gdb)\n",
    "                populate_field(gdb)\n",
    "                r_folder = '{}\\\\{}\\\\training_rasters'.format(base_folder, folder)\n",
    "                if os.path.exists(r_folder):\n",
    "                    shutil.rmtree(r_folder)\n",
    "                os.mkdir(r_folder)\n",
    "                print('copying rasters')\n",
    "                arcpy.management.CopyRaster('{}\\\\training_image_linear_composite'.format(gdb),\n",
    "                                           '{}\\\\training_image_linear_composite.tif'.format(r_folder),\n",
    "                                           pixel_type='8_BIT_UNSIGNED')\n",
    "                arcpy.management.CopyRaster('{}\\\\training_image_mssmall_composite'.format(gdb),\n",
    "                                           '{}\\\\training_image_mssmall_composite.tif'.format(r_folder),\n",
    "                                           pixel_type='8_BIT_UNSIGNED')\n",
    "                print('exporting training data')\n",
    "                with arcpy.EnvManager(scratchWorkspace=r\"C:\\\\capstone\\\\avy_resources\\\\sentinelsat\\\\sentinel_sat\\sentinel_sat.gdb\", \n",
    "                      workspace=r\"C:\\\\capstone\\\\avy_resources\\\\sentinelsat\\\\sentinel_sat\\\\sentinel_sat.gdb\"):\n",
    "                    arcpy.ia.ExportTrainingDataForDeepLearning(r\"{}\\\\training_image_mssmall_composite.tif\".format(r_folder), \n",
    "                                               r\"D:\\\\new_imagery\\\\UNET_TRAINING_IMAGES_MSSMALL\", \n",
    "                                               r\"{}\\\\training_polys\".format(gdb), \n",
    "                                               \"TIFF\", \n",
    "                                               128, \n",
    "                                               128, \n",
    "                                               64, \n",
    "                                               64, \n",
    "                                               \"ONLY_TILES_WITH_FEATURES\", \n",
    "                                               \"Classified_Tiles\", \n",
    "                                               0, \n",
    "                                               \"classvalue\", \n",
    "                                               0, \n",
    "                                               None, \n",
    "                                               0, \n",
    "                                               \"MAP_SPACE\", \n",
    "                                               \"PROCESS_AS_MOSAICKED_IMAGE\", \n",
    "                                               \"NO_BLACKEN\", \n",
    "                                               \"FIXED_SIZE\")\n",
    "                with arcpy.EnvManager(scratchWorkspace=r\"C:\\\\capstone\\\\avy_resources\\\\sentinelsat\\\\sentinel_sat\\sentinel_sat.gdb\", \n",
    "                      workspace=r\"C:\\\\capstone\\\\avy_resources\\\\sentinelsat\\\\sentinel_sat\\\\sentinel_sat.gdb\"):\n",
    "                    arcpy.ia.ExportTrainingDataForDeepLearning(r\"{}\\\\training_image_linear_composite.tif\".format(r_folder), \n",
    "                                               r\"D:\\\\new_imagery\\\\UNET_TRAINING_IMAGES_LINEAR\", \n",
    "                                               r\"{}\\\\training_polys\".format(gdb), \n",
    "                                               \"TIFF\", \n",
    "                                               128, \n",
    "                                               128, \n",
    "                                               64, \n",
    "                                               64, \n",
    "                                               \"ONLY_TILES_WITH_FEATURES\", \n",
    "                                               \"Classified_Tiles\", \n",
    "                                               0, \n",
    "                                               \"classvalue\", \n",
    "                                               0, \n",
    "                                               None, \n",
    "                                               0, \n",
    "                                               \"MAP_SPACE\", \n",
    "                                               \"PROCESS_AS_MOSAICKED_IMAGE\", \n",
    "                                               \"NO_BLACKEN\", \n",
    "                                               \"FIXED_SIZE\")\n",
    "print('total detections = {}'.format(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
